# ConfRadar Frontend Application - Product Requirements Document

## Purpose & Scope

ConfRadar is a web-based front-end application that lets researchers track academic conferences and their key dates (e.g. submission deadlines, notification dates, conference dates) in one place. The purpose of ConfRadar's frontend is to present up-to-date conference information in an intuitive interface, allowing users to discover conferences, monitor deadline changes, and export those dates to their personal calendars. This PRD focuses on the **front-end component** of ConfRadar - detailing what the application should do and how it should behave - and outlines the interactions with the back-end data service (which gathers conference metadata via web crawlers and LLM-based extraction).

**In Scope:** This document covers user-facing features (conference listings, search/filter, detail views, calendar export, settings for time zones) and developer-facing requirements (data models, API endpoints, performance criteria). It describes how the front-end will accommodate viewing conference metadata (name, location, dates, status, history of changes), filtering by various criteria (deadlines, location, etc.), toggling time zone displays, and exporting dates (Google Calendar, ICS format). It also defines non-functional requirements, design considerations, and an overview of how the front-end integrates with the back-end.

**Out of Scope:** The internal workings of the crawler/LLM system for data extraction are only briefly discussed for context. Implementation details of the crawling/LLM pipeline, user authentication (if any), or payment features are not in scope for this PRD. The focus is on the front-end requirements and how it interfaces with the back-end API.

## Background & Context

Academic researchers and organizers often struggle to keep track of numerous conference deadlines across various fields. Missing a submission deadline can mean a lost opportunity to publish research for an entire year. Traditionally, researchers have relied on community-maintained lists (like WikiCFP or static GitHub pages) or manual calendars to track these dates. For example, the AI research community had a popular deadline tracker maintained by PapersWithCode; when that was discontinued, the tool had to be migrated to a new host, illustrating how fragile and fragmented such solutions can be[\[1\]](https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca#:~:text=People%20often%20ask%20where%20to,has%20been%20adopted%20by%20HuggingFace). This underscores the need for a reliable, up-to-date system like ConfRadar.

Existing conference trackers demonstrate the demand for features like time zone handling and calendar integration. Many conferences set deadlines in **"Anywhere on Earth (AoE)" time** - meaning the deadline hasn't passed as long as it is still that date somewhere on Earth[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33). This can confuse users, so ConfRadar's front-end will automatically handle AoE time conversions and clearly indicate deadline times. Some current trackers (often field-specific) offer calendar exports; for instance, a blockchain conference tracker allows exporting all deadlines to Google Calendar or ICS format[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them). ConfRadar aims to generalize these ideas into a unified platform covering multiple research domains, with automation ensuring data accuracy and timeliness.

The back-end of ConfRadar will continuously crawl conference websites and calls-for-papers. Using Large Language Models (LLMs) for metadata extraction, it will parse unstructured text (e.g. websites or PDFs) to identify key details like conference name, acronym, location, dates, submission deadlines, notification dates, etc. These will be stored in a structured database. The front-end's job is to present this data effectively to end-users (researchers) and allow interaction (searching, filtering) without requiring them to manually sift through websites or social media for updates. When conference organizers change a deadline (e.g. an extension of the submission deadline), ConfRadar will reflect that update and even preserve a **change history**, so users can see if and when dates were modified.

By providing a central, user-friendly interface, ConfRadar saves researchers time and reduces the risk of missed deadlines. It is designed to be used by individual researchers planning submissions as well as by lab managers or professors overseeing multiple submissions. This PRD will ensure the front-end meets those users' needs with clarity and technical precision.

## Target Users & Personas

ConfRadar's frontend is designed for two primary user personas, with their goals and use cases informing the requirements:

- **Alice - The Busy PhD Student:** Alice is a third-year PhD student in computer science. She plans to publish at top conferences in AI and Systems. She needs to stay aware of upcoming submission deadlines and notification dates. Alice often juggles multiple projects, so she wants a quick way to **search and filter** for conferences in her field, sort them by upcoming deadline, and add those deadlines to her personal calendar. She values clarity (e.g. seeing how many days remain until a deadline) and up-to-date information (if a deadline gets extended, she wants to know). For Alice, ConfRadar is a planning tool to ensure she never misses an opportunity. (As an example of the impact, one tracker's users have reported success in planning submissions - e.g. a PhD student used a deadline tracker to target 5 top conferences in a year, getting 2 papers accepted[\[4\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C3%89xito%20de%20los%20estudiantes%20doctorales).)
- **Bob - The Research Lab Manager/Professor:** Bob leads a research group and oversees several students. He wants a broader overview of conferences across multiple domains (AI, Security, Networks) to help his team plan submissions. Bob might use ConfRadar to **filter by research area or conference location**, identify which conferences are coming up in the next quarter, and download an ICS file of all relevant deadlines to share with his group. He cares about data reliability (so he trusts the dates shown are correct) and might occasionally check the conference's status or changes (e.g. if a deadline was pushed back, indicating more time to prepare). Bob also appreciates any **timezone customization**, since his international team wants to see deadlines in their own local time, whereas he prefers the standardized AoE deadlines for consistency.

_(Secondary Persona:)_ **Carol - The Conference Organizer/Analyst:** (Future scope) Carol organizes conferences and also keeps an eye on scheduling of other events to avoid date conflicts. She might use ConfRadar to see a **calendar view** of all conferences in her domain or region. While not a primary target for v1, her needs influence features like a calendar export and location-based filtering.

These personas illustrate the need for a front-end that is easy to use for non-technical academics (straightforward search, clear labels), yet powerful enough for advanced users (filter combinations, data exports). Both value **timeliness and accuracy** of data, reinforcing the importance of the back-end's LLM-powered updates and the front-end's presentation of "last updated" info or change logs. The PRD's functional requirements will cater to these user goals.

## Functional Requirements

The following table lists the key functional requirements for the ConfRadar front-end. Each requirement has a unique ID for reference, a description of the functionality, and a priority indicating its importance for the initial release (High = must-have, Medium = nice-to-have, Low = optional or future).

| **ID** | **Functional Requirement** | **Priority** |
| --- | --- | --- |
| FR-1 | **Conference List View:** Display a scrollable or paginated list of conferences with key metadata: conference name (and acronym/year), location (city & country or "Virtual"), conference dates, and key deadlines (e.g. submission deadline). The list should also show status indicators (e.g. "Upcoming", "Deadline Passed", or "Submission Open/Closed") and optionally the last updated timestamp for each entry. | High |
| FR-2 | **Search by Name/Keyword:** Allow users to search for conferences by name, acronym, or keywords. The list should filter in real-time or on query submission to match the search term (e.g. typing "NeurIPS" shows Neural Information Processing Systems conference). | High |
| FR-3 | **Filter by Deadline Date:** Provide filters to narrow the list by deadline timing. For example, a user can filter for conferences with submission deadlines after a certain date or within a date range (e.g. "show deadlines in the next 3 months"). This helps users focus on upcoming opportunities. | High |
| FR-4 | **Filter by Location:** Allow filtering by conference location. Users might select a region or country (e.g. "Europe" or "USA") or choose "Virtual" to find online conferences. The front-end will then show only conferences matching that location criterion. | Medium |
| FR-5 | **Filter/Tag by Field or Category:** (If data is categorized) Support filtering by research field or conference category (e.g. AI, Systems, Biology). Users can narrow down to conferences relevant to their domain. _Note:_ This depends on the back-end providing a field/tag for each conference (e.g. "Machine Learning" tag). | Medium |
| FR-6 | **Conference Detail View:** When a user selects a specific conference (by clicking an entry in the list), display a detailed view. This includes the full conference name, website link, location details (venue, map link if available), dates of the conference, and a breakdown of all key dates (submission deadline, abstract deadline if separate, notification date, camera-ready deadline, etc.). The detail view should also show the current status (e.g. "Submission Open until Jan 10, 2026 AoE") and any notes (e.g. "Second round submissions" or other remarks). | High |
| FR-7 | **Change History Display:** On the conference detail view, provide a way to see the change history of key dates. For example, if the submission deadline was extended, the UI might show "Deadline was extended from Jan 5 to Jan 12 on Dec 20, 2025." This could be a collapsible section or an icon with tooltip that reveals past values. This lets users trust that they're seeing the latest info and understand any date changes. | High |
| FR-8 | **AoE Timezone Toggle:** Provide a toggle or setting to switch deadline time display between "Anywhere on Earth (AoE)" and the user's local time (or a chosen reference timezone). When AoE mode is on, all deadlines are labeled with "AoE" and use the AoE cutoff (UTC-12)[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33); when off, deadlines are converted to a user-selected timezone (default to user's local). This ensures users around the world can view deadlines in terms they understand. | High |
| FR-9 | **Custom Timezone Setting:** In the settings panel, allow the user to select a timezone (or use browser locale by default). All date-times (especially deadlines) in the UI will then be displayed in that timezone (except when AoE mode is explicitly toggled on). This setting affects both list and detail views and should persist for the user (e.g. saved in local storage). | Medium |
| FR-10 | **Sort & Highlight Deadlines:** Enable sorting of the conference list by certain columns, especially by upcoming deadline or by conference name. For example, a user might sort by deadline date ascending to see which deadlines are nearest. Additionally, the UI should visually highlight imminent deadlines (e.g. deadlines within 7 days could be shown with a warning color or an icon). This improves usability for scanning urgent items. | Medium |
| FR-11 | **Calendar Export (ICS):** Allow users to export conference deadlines to their calendar. Users should be able to download an **ICS file** or subscribe via a link. The ICS export can contain either all currently visible deadlines (e.g. the filtered list) or a subset (like a single conference's key dates). At minimum, provide a global export of all deadlines in the system (or all filtered deadlines) to ICS, as well as a per-conference export. For example, a "Export All Deadlines" button could generate an ICS with all upcoming deadlines (some existing trackers provide a single ICS for all listed deadlines[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them)). Each deadline should appear as an event in the ICS (with the title, date/time, and conference name). | High |
| FR-12 | **Google Calendar Integration:** In addition to raw ICS files, provide a one-click link to add deadlines to Google Calendar. This can be achieved by a URL that Google Calendar recognizes to import an ICS feed (as seen in existing tools[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them)). For example, an "Add to Google Calendar" link which, when clicked, opens Google Calendar with the subscription URL pre-filled. This makes it easy for users like Alice and Bob to keep their personal calendars in sync. | High |
| FR-13 | **Responsive Design:** The front-end should be usable on various devices (desktop, tablet, mobile). On smaller screens, the conference list might collapse some columns or use a card layout for readability. All features (search, filters, detail view, export) should be accessible on mobile devices as well. This ensures researchers can quickly check deadlines on the go. | High |
| FR-14 | **No Login Required (Public Access):** The application's core features should be available without requiring user login or accounts. A researcher can land on the site and immediately search/filter conferences and export data. (In future, if personalization is added, an account system might be introduced, but it's not needed for the base functionality.) | High |
| FR-15 | **Settings Persistence:** Any user preferences (like selected timezone, AoE toggle, or filters) should persist at least within a session (and ideally across sessions via local storage or cookies). For example, if Bob turns on "show deadlines in AoE" and refreshes the page, the app should remember this setting. This improves user experience by not forcing repeated configuration. | Medium |
| FR-16 | **Error Handling & Data Refresh:** The frontend should handle cases where data is not available or an API call fails gracefully. For instance, if the conferences list fails to load, show a user-friendly error message and a retry option. Also, provide a manual "Refresh Data" action (or auto-refresh at intervals) so users can fetch the latest updates on demand. This complements the back-end's periodic updates (which occur behind the scenes typically)[\[5\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C2%BFCon%20qu%C3%A9%20frecuencia%20se%20actualizan,los%20datos%20de%20las%20reuniones). | High |

_Note:_ The above requirements focus on the front-end behavior. They assume the back-end API provides the necessary data (conference details, filters, etc.) to fulfill them. The priorities reflect that core browsing and exporting features (FR-1, FR-2, FR-6, FR-8, FR-11, FR-12, etc.) are crucial for launch, while some refinements (FR-4, FR-5, FR-9, FR-10, FR-15) can be added if time permits or in subsequent updates.

## Non-Functional Requirements

Beyond specific features, the ConfRadar frontend must meet certain non-functional criteria to ensure it is robust, user-friendly, and maintainable:

- **Performance:** The application should be lightweight and fast. Conference list data (potentially hundreds of entries) should load within a couple of seconds on a typical connection. UI interactions (searching, filtering) should feel instantaneous (target under 300ms for filtering client-side). The front-end will use efficient rendering so that sorting or toggling timezones doesn't lag even with many items. If server-side queries are used for filtering, the API should respond quickly (under 1-2 seconds for complex queries).
- **Scalability:** The design should handle an increasing number of conferences and users. Initially, it might track a few hundred conferences across fields, but it could grow to thousands. The UI should accommodate this by using pagination or virtual scrolling for long lists, and the search/filter feature should be able to narrow down results quickly. On the user load side, the front-end should be deployable on a CDN or scalable hosting to handle spikes (e.g. around popular deadline seasons) without downtime.
- **Reliability & Data Freshness:** ConfRadar's value depends on accurate data. The system should ensure that the data shown is as recent as the last crawl/update. The UI might display a "Last updated X hours ago" indicator for transparency. If the back-end update frequency is e.g. every 6 hours[\[5\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C2%BFCon%20qu%C3%A9%20frecuencia%20se%20actualizan,los%20datos%20de%20las%20reuniones), the front-end should fetch updates accordingly (maybe refresh data daily or on user action). The front-end must also handle partial data gracefully (for example, if a conference is announced but some dates TBA, it should show "TBA" rather than nothing or a broken field).
- **Usability & Clarity:** The interface should be intuitive. This means using clear labels (e.g. "Submission Deadline (AoE)" explicitly noted), tooltips or help icons to explain concepts like "AoE" for new users, and a clean layout that isn't cluttered. Paragraphs and list items should be concise. We aim for minimal clicks to find information: from the main list, one click to see all details of a conference, one click to export to calendar, etc. The application should follow UI design best practices so that even users who are not tech-savvy can navigate it (e.g. professors who just want to quickly see deadlines).
- **Accessibility:** Ensure the frontend adheres to accessibility standards (WCAG 2.1 AA as a baseline). This includes proper contrast for text, support for screen readers (all important information should be in text or have alt-text, since some academics with visual impairments might use the tool), and keyboard navigability (users can tab through filters and open details without a mouse). For example, if we have a toggle for AoE, it should be focusable and have an aria-label like "Toggle AoE timezone".
- **Cross-Browser Compatibility:** The application should work on modern browsers (Chrome, Firefox, Safari, Edge) and degrade gracefully on older versions. Also, both desktop and mobile browsers should be supported (see Responsive Design in FR-13). We will test on major browser latest versions to ensure consistent behavior.
- **Security:** Although the app mostly displays public data, we still ensure basic security. All API calls should be made over HTTPS to protect data integrity. If any user data is involved (like an email for alerts in future), it must be handled securely. The front-end should also be written to avoid common vulnerabilities (e.g. no XSS via any dynamic content; any user-provided input in search filters should be sanitized or parameterized to avoid injection issues on the API side).
- **Maintainability:** The front-end codebase should be organized and documented for ease of updates. As conferences and fields evolve, developers might need to add new filters or adjust data fields. Using a modular architecture (components for list, filters, etc.) and clear separation of concerns (e.g. services for API calls, components purely for display) will be required. Additionally, the code should be written in a way that it's easy to plug in enhancements (like new export formats) in future phases.
- **API Error Tolerance:** The UI should handle slow or failing API responses gracefully (displaying loaders and error messages, as noted in FR-16). The system should be resilient such that a glitch in the back-end doesn't break the front-end experience entirely. Implementing client-side caching for data (so if the user has visited recently, they see slightly older data rather than nothing) can be considered.
- **Data Accuracy and Consistency:** Because ConfRadar uses LLM-based extraction on the back-end, there is a non-functional need to ensure any anomalies are caught. For front-end, this means possibly indicating if a piece of data is unverified or tentative (for example, if the LLM wasn't fully confident). However, ideally the back-end validation ensures only accurate data is shown. From the user perspective, they should rarely if ever encounter incorrect dates; if they do, there should be a feedback channel (in future) or at least a visible source link to verify (like a link to the official conference site for cross-reference).

In summary, the front-end must not only provide the right features but also deliver them in a fast, reliable, and user-friendly manner. These non-functional requirements ensure that ConfRadar becomes a dependable daily tool for researchers like Alice and Bob.

## UX/UI Design Considerations

In designing ConfRadar's user interface, we focus on clarity, ease of navigation, and presenting complex data (dates and times across time zones) in a digestible format. Here are key design considerations and decisions:

- **Layout & Navigation:** The app will use a simple layout - a top header with perhaps the app name and a settings icon, a main content area for the conference list, and a side or top toolbar for search and filters. The **conference list view** might be in a table format for desktop (columns for name, location, deadline, status) to utilize wide screens, while on mobile it might switch to a card layout (each conference in a card showing those details stacked). Key actions like search bar and filter toggles should be prominently placed (e.g. a search input at top, filter drop-downs or icons adjacent).
- **Conference List Items:** Each conference entry in the list should highlight the **conference name** (with year or acronym), and directly underneath or next to it, show the next upcoming deadline date. We might include a subtle countdown indicator - e.g. "Submission Deadline: Jan 10, 2026 (12 days remaining)" - to draw attention to urgency (some existing apps use a countdown for the next deadline[\[6\]](https://github.com/huggingface/ai-deadlines#:~:text=You%20can%20add%20any%20custom,in%20the%20conference%20details%20card)). The location and conference dates can be shown in a smaller font or secondary line. If a deadline has passed, the entry could be greyed out or marked as "Closed" to de-emphasize it. We might also use small badges or color-coding for status: e.g. green "Open", red "Closed", blue "Ongoing (Conference week)", etc.
- **Filters & Search UI:** The search bar will support quick text queries. Filters (deadline range, location, field) can be presented as either a sidebar or a dropdown panel. For example, clicking a "Filters" button could open a multi-select menu where the user picks one or more locations or categories, and a date picker for the deadline range. On desktop, a persistent sidebar might list filters with checkboxes (for fields, locations) and sliders/date-pickers (for date). The UI should make it obvious when filters are active (e.g. showing chips or tags for each active filter that the user can remove). A "Clear filters" option is important for usability.
- **AoE Toggle & Timezone:** Given the importance of time zone, the UI will have a clearly visible toggle switch labeled "AoE" (perhaps with a tooltip "Anywhere on Earth - last timezone on Earth (UTC-12)"). When this is ON, deadlines show the "AoE" label and times; when OFF, a dropdown or label indicates the current timezone (e.g. "Times shown in \[Europe/London\]"). Possibly the header or footer of the list can display "All deadlines in AoE time" vs "All deadlines in GMT+1 (London Time)" to avoid per-item clutter. Changing this setting should update all displayed times immediately. We will ensure that if a user's local timezone is used, it's clearly noted to avoid confusion. (For instance: _Deadline: Jan 10, 2026 23:59 (AoE)_ vs _Deadline: Jan 11, 2026 11:59 GMT+8_ for a user in GMT+8 zone.)
- **Conference Detail Page:** The detailed view (likely a separate page or modal) should provide a structured outline of all info. At the top: conference full name, acronym, year, and maybe series info. A link to the official website (with an external link icon) should be right there. Then a section for "Conference Dates & Location" (e.g. _July 1-5, 2026 in Paris, France_ with possibly a small map or a link to Google Maps[\[7\]](https://blockchain-deadlines.github.io/#:~:text=June%2022,New%20York%20City%2C%20NY%2C%20USA)). Next, a section for "Important Dates" listing all deadlines and key dates. This can be a list or table: for example:

| Deadline | Date & Time (AoE / Local) |
| --- | --- |
| Abstract Registration | Jan 5, 2026 23:59 AoE |
| Submission Deadline | Jan 10, 2026 23:59 AoE |
| Author Notification | Mar 1, 2026 (date only) |

Each date might be followed by a timezone note depending on settings. If any dates are in the past relative to today, they could be styled differently (e.g. strikethrough or a "(Passed)" note). If a deadline is tentative or TBA, show "TBA".

After listing dates, the detail view can have a "History" or "Updates" accordion. Clicking it reveals any changes (e.g. _"Submission Deadline extended from Jan 5 to Jan 10 on Dec 20, 2025."_). This info should be presented in a concise, chronologically ordered list for transparency.

Finally, on the detail page, include an **export section**: buttons to "Add this conference to Calendar" (which could generate an ICS for just this conference's dates) and perhaps "Subscribe to updates" (if in future we allow notifications or email alerts).

- **Export/Calendar UI:** For ICS/Google Calendar export (FR-11, FR-12), we will likely not show raw links to ICS (to avoid user confusion). Instead, use buttons: one with Google Calendar logo "Add to Google Calendar", another with an icon "Download .ICS". For the Google Calendar integration, clicking the button will redirect to Google Calendar's interface with the ICS URL pre-filled (similar to how some sites do it[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them)). We will inform the user if needed (maybe a tooltip like "Opens Google Calendar to subscribe"). The ICS download can trigger a file download; after clicking, a small toast message "ICS file generated" can appear. We should ensure to let the user know what the ICS contains (if it's all deadlines or filtered ones). If we implement export for "only filtered conferences", the UI might present that option (e.g. a text saying "Export \[5\] filtered deadlines to ICS").
- **Visual Design:** ConfRadar should have a clean, academic feel. We might use a neutral color scheme (blues or greens) and a simple font. The emphasis should be on content, so avoid overly decorative elements. Use icons to enhance comprehension: e.g. a calendar icon for dates, a clock or hourglass icon for deadlines, a globe icon for AoE or timezone. Each conference entry could have a small icon if it's a known series (not mandatory, but e.g. a generic icon or logo if available could help identify quickly - however, we must be careful with copyright if using logos; perhaps stick to text acronyms).
- **Mobile Considerations:** On mobile, the design should stack elements vertically. The search bar might become a search icon that expands. Filters could become a slide-out panel. The list might show just name and a short summary, with tapping expanding to show deadlines. The detail view might be a separate screen. All interactive elements (buttons, toggles) must be large enough to tap easily.
- **Feedback & Help:** Include a way for users to know the data source or to report issues. For example, each conference detail might say "Source: Extracted from official site - \[View\]" linking to the CFP page (to increase trust). A "Report a problem" link in footer or detail view could let users flag if a date seems wrong (for future enhancement, maybe opens a mailto or feedback form).
- **State Indications:** While data is loading, show a spinner or skeleton list so users know something is happening. If no conferences match the filters/search, show a friendly message like "No conferences found for your criteria. Try adjusting filters." rather than a blank screen.

In summary, the UI is designed to be **information-centric**: the goal is that in a quick glance, a user can see what conferences are coming up and when, and with one or two clicks, they can drill down or export that info. ConfRadar's design will hide complexity (like time zone calculations) behind simple toggles and clear text, so both Alice and Bob can confidently use it without confusion.

## Data Model & API Contracts

The front-end will interact with the back-end via a set of RESTful API endpoints. This section describes the core data model (what information is stored for each conference) and the contract of the API (endpoints, request/response formats). All data exchanges will use JSON for ease of use in the frontend (except when fetching ICS files).

### Data Model

**Conference Entity:** Each conference in ConfRadar is represented as a structured object. Key fields include:

- id: **String**, a unique identifier for the conference (e.g. "ICML2026" or an internal UUID). This is used for referencing in URLs (like /conferences/ICML2026).
- title: **String**, the short name or acronym of the conference (e.g. "ICML").
- year: **Number**, the year of the edition (e.g. 2026).
- full_name: **String**, the full official name (e.g. "International Conference on Machine Learning").
- website: **String**, URL to the official conference page or CFP.
- location: **String**, location of the conference (city, country or "Virtual"). This might be further broken into city and country fields in the data model.
- dates: **String**, the conference event dates (e.g. "July 10-15, 2026"). We may also have structured start and end dates: start_date and end_date (ISO format date) for clarity.
- timezone: **String**, the primary timezone of the conference location or deadlines (e.g. "UTC" or "America/New_York"). This is relevant if deadlines are given in a specific timezone on the CFP; often, if deadlines are AoE, this might be "AoE". We'll store it to know how to interpret raw times.
- deadlines: **Array of Deadline Objects** - each deadline object includes:
- type: **String**, type of deadline (e.g. "submission", "abstract", "notification").
- label: **String**, a human-readable label for the deadline (e.g. "Full Paper Submission Deadline").
- date: **String**, the date/time of the deadline in ISO 8601 format (e.g. "2026-01-10T23:59:00"). We will include timezone offset or assume UTC for storage.
- timezone: **String**, the timezone that the deadline time is relative to (e.g. "AoE" or "UTC-08:00"). This allows conversion to user's timezone or AoE.
- (Optional) notes: **String**, any note like "extended" or "strict deadline" if relevant.
- status: **String**, computed status of the conference with respect to submission. For example, "Upcoming (Open)", "Submission Closed", "Conference Ongoing", "Concluded". This can be derived from dates but is stored or computed by backend for quick reference.
- last_update: **String (date-time)**, timestamp of when this conference's data was last verified/updated by our system. E.g. "2025-12-01T12:00:00Z". The frontend can display this or use it internally for caching.
- change_history: **Array of Change Objects** - each capturing a change in a key date:
- date: **String (date)** when the change was detected (e.g. "2025-12-20").
- field: **String** what was changed (e.g. "submission_deadline").
- old_value: **String** previous date/time or info (e.g. "2025-12-30 23:59 AoE").
- new_value: **String** new date/time or info (e.g. "2026-01-05 23:59 AoE").
- (Optional) reason: **String** if available, maybe a note like "Deadline extended by organizers" (likely not automatically available, but could be manually added or parsed).
- tags or field: **String or Array** indicating the research field/category (e.g. "machine learning", "AI"). Could be multiple if conference is interdisciplinary.

An example conference record in JSON (for illustration) might look like:

{  
"id": "ICML2026",  
"title": "ICML",  
"year": 2026,  
"full_name": "International Conference on Machine Learning",  
"website": "<https://icml.cc/2026/>",  
"location": { "city": "Vienna", "country": "Austria" },  
"dates": "July 10-15, 2026",  
"start_date": "2026-07-10",  
"end_date": "2026-07-15",  
"timezone": "UTC-12", // AoE equivalent  
"deadlines": \[  
{  
"type": "abstract",  
"label": "Abstract Registration Deadline",  
"date": "2026-01-03T23:59:59",  
"timezone": "UTC-12"  
},  
{  
"type": "submission",  
"label": "Paper Submission Deadline",  
"date": "2026-01-10T23:59:59",  
"timezone": "UTC-12"  
},  
{  
"type": "notification",  
"label": "Author Notification Date",  
"date": "2026-03-15",  
"timezone": "UTC" // date-only, treated as UTC date  
}  
\],  
"status": "Submission Closed (Deadline passed)",  
"last_update": "2025-12-25T08:00:00Z",  
"change_history": \[  
{  
"date": "2025-12-20",  
"field": "submission_deadline",  
"old_value": "2026-01-05 23:59 AoE",  
"new_value": "2026-01-10 23:59 AoE"  
}  
\],  
"tags": \["machine learning", "AI"\]  
}

This structure covers the essential data needed by the front-end. Note that the back-end's use of LLMs is abstracted away - by the time data reaches the front-end, it's structured and cleaned. The above example is inspired by typical conference info; in practice our actual data model might have slight differences (for example, some trackers include an id like bestconf22 and fields like hindex to indicate conference rank[\[8\]](https://github.com/huggingface/ai-deadlines#:~:text=src%2Fdata%2Fconferences%2F,the%20importance%20of%20a%20conference)).

It's important to highlight that the deadlines field is a list, allowing multiple deadlines to be associated with one conference (common for conferences with abstract vs full paper deadlines, or multiple rounds). The front-end will often display the _next upcoming deadline_ prominently - which can be derived by looking at the deadlines array and finding the soonest date in the future[\[6\]](https://github.com/huggingface/ai-deadlines#:~:text=You%20can%20add%20any%20custom,in%20the%20conference%20details%20card). All deadlines (upcoming and past) will be shown on the detail page in chronological order.

### API Endpoints

The ConfRadar back-end will expose REST API endpoints that the front-end uses. All endpoints are prefixed with /api (for example), and return data in JSON unless otherwise noted. Below are the primary endpoints:

- **GET /api/conferences** - _Retrieve a list of conferences._ This endpoint returns an array of conference objects (as described above). It supports query parameters for filtering and searching:
- ?search=&lt;query&gt; - filter by name or keyword (case-insensitive match on conference title or full_name).
- ?field=&lt;tag&gt; - filter by research field/tag (e.g. field=AI to get AI conferences).
- ?location=&lt;country_or_region&gt; - filter by location (e.g. location=USA or location=Europe). We may define specific region keywords in documentation.
- ?after=&lt;date&gt; - only include conferences with a submission deadline on or after this date (e.g. after=2026-01-01).
- ?before=&lt;date&gt; - (if needed) conferences with submission deadlines before a date.
- ?sort=&lt;key&gt; - sort the results by a field, e.g. sort=deadline or sort=name. Possibly allow sort=-deadline for descending.
- ?tz=&lt;timezone&gt; - (Optional) specify a timezone to convert deadline times into before returning. For example, tz=America/New_York could make the API respond with deadlines in that timezone. If not provided, the API might default to storing times in UTC or AoE and sending those along with timezone info for the front-end to handle. (This parameter is an enhancement - the front-end could also just do conversion itself if it has the raw data.)

**Response:** JSON array of conference summaries. To keep the list lightweight, the API might not send all details (like change_history or full deadlines list) in this call. It could send key fields (id, title, location, next_deadline, status). For each item we might have:

\[  
{  
"id": "ICML2026",  
"title": "ICML",  
"full_name": "Int. Conf. on Machine Learning",  
"year": 2026,  
"location": "Vienna, Austria",  
"next_deadline": {  
"label": "Submission Deadline",  
"date": "2026-01-10T23:59:59",  
"timezone": "UTC-12"  
},  
"status": "Open"  
},  
{ ... },  
...  
\]

This keeps the payload smaller. If more details are needed, the front-end will call the detail endpoint. The API will typically return HTTP 200 with this data, or appropriate error codes (400 for bad query, etc.). Pagination: If the number of conferences is large, the API may paginate (e.g. GET /api/conferences?page=2&limit=100), but initially we expect a manageable number and can load all and filter client-side.

- **GET /api/conferences/{id}** - _Retrieve detailed info for a specific conference._ The {id} path parameter is the conference's unique ID or slug. The response is a JSON object with all the fields of the conference (as described in data model, including the full deadlines list and change_history). Example: GET /api/conferences/ICML2026 returns the full JSON as in the example above. If the conference is not found, returns 404.
- **GET /api/conferences/{id}/history** - (Optional, if not included in detail) A sub-endpoint to get just the change history. This could be used if we want to lazy-load the history when user opens it. Alternatively, history is included in the detail payload to simplify.
- **GET /api/calendar/ics** - _Get an ICS calendar file of deadlines._ This endpoint generates an iCalendar (.ics) file on the fly (or returns a static file) containing events for conference deadlines. It can support query parameters to filter which events:
- Without params, it might return **all upcoming deadlines** in the system as events (which a user can subscribe to in full). This was the approach in some trackers where one ICS contains everything[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them).
- It could accept the same filters as the main list (so an ICS of "just AI conferences" or "just deadlines before a date"). For example, GET /api/calendar/ics?field=AI&after=2026-01-01 would return an ICS with deadlines for AI conferences after Jan 2026. In the first version, we might keep it simple (maybe an ICS of whatever list was retrieved, but that coupling requires state; easier is to repeat filters in the query).
- It could also accept an id or list of ids, but easier is separate endpoints:
  - **GET /api/conferences/{id}/ics** - returns an ICS file for that one conference (with perhaps multiple events: submission deadline, notification, etc., each as a calendar event).

The ICS generation on the back-end will use the conference data to create events with summary like "&lt;Conference Name&gt; - &lt;Deadline label&gt;" and the date/time. All times in ICS can be in UTC or a specified TZ; often AoE deadlines can be converted to UTC-12 offset in ICS. Users can then import this into Google Calendar, Outlook, etc.

**Response:** Content-Type: text/calendar with the .ics content. The front-end likely doesn't process this JSON but triggers a download. (This endpoint is what the "Download ICS" button will hit, possibly as a direct link.)

- **GET /api/calendar/google** - (Optional convenience) This could redirect to Google Calendar with a proper link. However, typically we can use the same ICS link: Google Calendar import can be done by giving it the ICS URL (as seen with the example where a Google Calendar link references the .ics URL[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them)). So we might not need a separate endpoint; the front-end can embed the ICS URL in a Google Calendar UI link. For instance:
- <https://calendar.google.com/calendar/r?cid=&lt;ics_url_encoded>&gt;
- Where &lt;ics_url_encoded&gt; is the URL to our ICS feed. So no dedicated API needed for Google; just documentation on how to form that link.
- **POST/PUT Endpoints:** In the initial scope, we likely don't have user-generated content, so no creates/updates from front-end. Conference data updates come from the back-end pipeline, not user input. If in future we add user accounts or allow suggestions, endpoints like POST /api/user/settings or POST /api/alerts (for setting an email alert) might appear, but they're beyond this scope.
- **Error format:** The API should provide error messages in JSON as well, e.g. { "error": "Conference not found" } for a 404, or { "error": "Invalid query parameter" } for a 400. The front-end will interpret these to show user-friendly messages.
- **Rate & Caching:** The front-end will likely cache the list of conferences in memory once loaded to avoid refetching repeatedly. However, if needed, the API might support ETag or Last-Modified headers so the front-end can re-validate cached data periodically. Given that data changes maybe a few times a day at most, this is manageable.

To ensure clarity, here's a quick reference example of using the API:

- _User opens app:_ Front-end calls GET /api/conferences (possibly with no filters) to get all upcoming conferences. The response is used to render the list.
- _User types "Security" in search:_ Front-end either filters client-side or calls GET /api/conferences?search=Security to get filtered list.
- _User selects a conference:_ Front-end navigates to /conference/{id} page, and calls GET /api/conferences/{id} to get detail (unless it already has all data from initial list, which it might not for history etc).
- _User toggles AoE:_ This might not require an API call - front-end can convert times (since it knows the original time and timezone from data). However, if we decided to let the server do conversion, it could call e.g. GET /api/conferences?id=ICML2026&tz=Europe/London to get times in a specific tz. Most likely we'll do it client-side using a library like moment.js or Luxon, to avoid extra round trips.
- _User clicks "Add to Google Calendar":_ Front-end will open a new tab to a URL like <https://calendar.google.com/calendar/r?cid=https://conf-radar.org/api/calendar/ics> (the encoded ICS feed URL). Google will fetch and subscribe.
- _User clicks "Download ICS" for one conference:_ Front-end does GET /api/conferences/ICML2026/ics - which either triggers a download or the front-end receives the file blob and then triggers a download.

Throughout, the API and data model are designed to be **developer-friendly**. Clear field names (matching those in UI where possible) and consistent formats (ISO dates, including timezone info) will minimize confusion. We will provide API documentation alongside this (in Documentation & Deliverables) for developers implementing or consuming the API. The structure aligns with what similar projects have used (for instance, the huggingface/ai-deadlines project uses YAML with fields like title, year, deadlines, timezone, city, country, note which correspond closely to our model[\[8\]](https://github.com/huggingface/ai-deadlines#:~:text=src%2Fdata%2Fconferences%2F,the%20importance%20of%20a%20conference)).

## Timeline & Milestones

To deliver the ConfRadar front-end, we propose the following timeline with key milestones. This assumes the back-end and data extraction components are developed in parallel, as they are prerequisites for some front-end functionality. Dates here are tentative and can be adjusted based on project start date (assuming project kickoff in Nov 2025 for example):

- **Nov 2025 - Requirements & Design Complete:** Finalize PRD (this document) and get stakeholder sign-off. Create initial UX wireframes for the list view, detail view, and key UI elements (filters, toggles, export dialog). _(Deliverables:_ low-fidelity prototypes, confirmed tech stack selection for front-end.)\*
- **Dec 2025 - Core Front-End Structure:** Set up the front-end project (e.g. using React or Vue, with necessary libraries for routing, state management, date handling). Implement the basic page layout, routing (list page and placeholder detail page), and integrate a mocked API or sample data. By end of Dec, have a **basic conference list** rendering from a static JSON to demonstrate structure and styling.
- **Jan 2026 - API Integration & List View Beta:** By mid-Jan, the front-end should be calling the real back-end API (or a staging version) to populate the conference list. Implement search (FR-2) and basic filtering (FR-3, FR-4) in the UI, initially maybe client-side with the fetched data. The list view should be largely functional: user can search/filter and see results update. Also implement the responsive design aspects so it works on mobile. **Milestone:** End of Jan, **Beta version of the conference list** page is ready for internal testing (with live data flowing in).
- **Feb 2026 - Conference Detail & Calendar Export:** Implement the conference detail view (FR-6) fully. This includes showing all deadlines, status, and integrating change history (which requires back-end support). By mid-Feb, the detail page should display actual data from GET /conference/{id} including an initial version of change history display. Simultaneously, implement the calendar export functionality: generate ICS via the API and ensure the Google Calendar link works. Test that events show correctly with the right timezones in external calendars. Also implement the AoE toggle and timezone setting (FR-8, FR-9) around this time, since it affects both list and detail display. **Milestone:** End of Feb, **Feature-complete front-end** - all major features (list, detail, search/filter, toggles, export) are implemented. At this point, we should have a fully usable product in a staging environment.
- **Mar 2026 - Testing & QA, Polish:** Spend this month on rigorous testing and bug fixing. Test the UI with various scenarios: hundreds of conferences loaded, filters combined, mobile browsers, different timezones (simulate user in different locale), etc. Ensure accessibility features (e.g. screen reader labels, keyboard nav) are in place. Also refine the UI/UX details: e.g. maybe add a countdown timer display for next deadlines, improve loading spinners, etc. If any non-critical features were left (like FR-5 field filtering or FR-10 sorting), implement them now as time permits. **Milestone:** Mid-to-late March, **Release Candidate (RC)** ready - meaning the app is ready for a limited beta release to friendly users for feedback.
- **Late Mar 2026 - Beta Launch:** Release ConfRadar front-end to a small group of users (or internally) to gather feedback. This might include select researchers who can try it on real use cases. Use their feedback to catch any usability issues or minor missing features (perhaps they might request an additional filter or clarity in labels).
- **Apr 2026 - Public Launch (v1.0):** Aim for an early April official launch of ConfRadar. By this time, documentation is ready, and any last-minute fixes from beta feedback are in. The system should be populated with all known conferences for the year, so new users see value immediately. Announce to relevant communities (perhaps via mailing lists or social media, if applicable).
- **Post-launch (May - Jun 2026):** Monitor usage, address any urgent bugs. This period can also be used to implement any stretch features or improvements identified earlier but not critical for v1 (some items in Future Roadmap or lower-priority FRs). For example, if not done, adding more filter categories or a calendar view can be started here. However, these would be part of a **Phase 2** release later.

Each milestone will be tracked with specific deliverables (see Documentation & Deliverables section for what accompanies each stage). The timeline above is aggressive but feasible given the mostly straightforward nature of the front-end (assuming back-end data is ready on time). Regular sync with back-end team is necessary, especially for data model alignment and any changes needed as we test with real conference data.

We also build in time for iterative refinement - the Beta period in late March is crucial to ensure the product meets user needs. Success at launch will be measured not just by hitting the date but by delivering a stable, useful tool, so schedule adjustments will be made if quality isn't there (for instance, we'd rather slip launch by a couple of weeks than launch with broken export or incorrect data rendering).

## Success Metrics

To evaluate the success of the ConfRadar front-end (and the product overall), we will track a variety of metrics, focusing on both user engagement and data reliability. The following success metrics will be considered:

- **Adoption & Usage:** Number of unique users (researchers) using ConfRadar per month. Our goal might be to reach (for example) 1000 active users within the first 3 months of launch. Additionally, track daily active users (DAU) vs. monthly (MAU) to see retention - e.g. an indication that researchers are integrating it into their routine.
- **Session Duration & Engagement:** Average time spent on the site per session, or average pages viewed. If users regularly browse multiple conferences or spend time filtering, it indicates the tool's usefulness. We expect a typical user session to involve checking deadlines - possibly a few minutes long. Very short sessions might indicate they aren't finding what they need, whereas moderately long sessions (or repeated sessions) show engagement.
- **Search/Filter Utilization:** How often are features like search and filters used? If a large portion of users use the search bar or apply filters, it confirms those features' importance. We can log events like "filter by location used" or "AoE toggle switched" to gauge interest. For example, if 70% of users enable AoE view, that's a key insight (and success in addressing the AoE need).
- **Calendar Export & Integration:** Number of ICS downloads or Google Calendar link clicks. This indicates how many users are converting the data into their personal workflow. For instance, if within the first month, 200 ICS subscriptions are created, that's a strong sign that users trust and rely on the data (because they're willing to integrate it into their calendars).
- **Data Coverage & Freshness:** Although more of a back-end metric, it reflects on front-end user satisfaction. We can measure how up-to-date the information is: e.g. percentage of conferences where the deadline info is current and not outdated. If the system catches 95% of deadline extensions within a day and reflects them, that's a metric of data freshness. A success threshold might be "All known changes to deadlines are updated in the UI within 24 hours of announcement"[\[5\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C2%BFCon%20qu%C3%A9%20frecuencia%20se%20actualizan,los%20datos%20de%20las%20reuniones). We can indirectly assess this by verifying with random checks or via user feedback (if users report an outdated deadline, that's a miss).
- **Error Rates and Performance:** Track front-end error rates (e.g. API calls failing). We want a high success rate for data loads (>99% of API calls succeed without error). Page load time metrics: e.g. Time to Interactive should be low (a few seconds). Using monitoring tools, we could set goals like "Initial data load under 3 seconds on average" and track against that. Low error reports from users (few support tickets or bug reports) is also a quality metric.
- **User Satisfaction:** Qualitative but can be quantified via surveys or feedback forms. We could provide an optional feedback mechanism ("Did ConfRadar help you? Rate 1-5"). High average ratings or testimonials like "I submitted to 3 conferences thanks to ConfRadar" would indicate success. Since user feedback is key in academic circles, an NPS (Net Promoter Score) or similar measure after initial usage could be collected.
- **Recurring Usage:** A critical sign of success is if users keep coming back. If a user only comes once, finds a date, and leaves, it's useful but not as sticky. We'd like to see a decent percentage of users returning multiple times per month (especially around the time when deadlines are approaching or new CFPs come out). For example, a metric could be "50% of users who sign up (or first use) return at least 3 times in the next two months."
- **Coverage of Conferences:** Number of conferences tracked in the system vs. known conferences in that domain. For instance, if in AI we aim to track the top 50 conferences and we have 48, that's 96% coverage. This metric ensures our content offering is comprehensive, which drives user satisfaction (if they can find _most_ conferences they care about). We can compare against external lists or user suggestions of missing conferences.
- **Conversion to Alerts (if applicable):** If in future we have a feature like email alerts or account sign-ups, the conversion rate of visitors to sign-ups is a metric. For now, lacking user accounts, a proxy could be "how many subscribe to the ICS feed" as noted or "how many share the link with colleagues" (could be tracked by copy link events or referrals).

Success for ConfRadar will ultimately be measured by it becoming a go-to resource for researchers. A leading indicator of that is community adoption - e.g. being referenced in researcher forums or lab mailing lists. While not a straightforward metric, we might monitor referrals or mentions. For the front-end team, hitting the quantitative targets (user counts, low error rates) and seeing steady growth in usage will define a successful launch and guide where to iterate next.

## Risks & Mitigations

Like any product, ConfRadar faces several risks that could impede its success. Below we identify key risks and how we plan to mitigate them:

- **Risk: Data Inaccuracy or Gaps.** Because the system relies on crawlers and LLM extraction, there is a chance that some conference data is parsed incorrectly (e.g. an LLM misreads a date) or that some conferences are missed entirely. If users find wrong information, trust in the product could be undermined.  
    **Mitigation:** Implement verification steps in the back-end (e.g. cross-check extracted dates with known patterns or have a human curator oversee critical conferences). For the front-end, clearly cite the source or provide a link to the conference CFP so users can double-check[\[1\]](https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca#:~:text=People%20often%20ask%20where%20to,has%20been%20adopted%20by%20HuggingFace). Additionally, provide a feedback mechanism for users to report suspected errors, so we can quickly correct data. Over time, use feedback and improved parsing to reach near 100% accuracy. We might also label data that is less certain (though ideally we avoid showing unconfirmed data at all).
- **Risk: Conference Website Changes & Crawling Issues.** Conference pages might have different formats or could change after initial posting (which is partly why we have change tracking). If the crawler fails to pick up a change (like a deadline extension announced on Twitter instead of the website), users could miss updates.  
    **Mitigation:** Diversify data sources - do periodic manual sweeps or integrate with community inputs (in future, possibly allow logged-in users to submit updates). Use the change history feature to at least log when updates do happen. Ensure the crawler schedule is frequent around critical times (like near deadlines)[\[5\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C2%BFCon%20qu%C3%A9%20frecuencia%20se%20actualizan,los%20datos%20de%20las%20reuniones). For front-end, encourage users to check "last updated" and not solely rely if in doubt. Eventually, possibly tie into APIs or feeds if conferences provide iCal of their dates, to automatically stay synced.
- **Risk: Load and Performance under heavy use.** If the tool becomes popular (many users or many conferences), the front-end might slow down (especially if filtering large lists client-side) or the back-end might see high load on the API.  
    **Mitigation:** The front-end will use optimized techniques (like virtual scrolling to only render visible items, debounced search input to avoid flooding requests). We will also implement pagination or lazy-loading if data volume grows. On the back-end side, caching frequently requested data (like the full conference list) and using CDN for static responses (e.g. the ICS file can be cached since it updates only periodically) can reduce server load. We'll also do load testing ahead of launch to ensure the system can handle expected traffic. Scaling the hosting (cloud infrastructure) is another mitigation if usage exceeds expectations.
- **Risk: Timezone Confusion and Errors.** Handling timezones and AoE is complex; mistakes could lead to showing incorrect deadline times to users (a serious issue). For example, if AoE conversion is off by a day, users might think they have an extra day.  
    **Mitigation:** Use well-tested libraries for date/time conversion and thoroughly test edge cases (especially around daylight savings changes, year boundaries, etc.). We will explicitly test a known scenario: AoE means UTC-12 (like Baker Island time)[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33) - we'll ensure that converting AoE to local time and vice versa always yields the correct "still open" logic. In the UI, we will also display the timezone to avoid ambiguity (so even if conversion is wrong, a savvy user might catch "that says PST, not AoE"). Additionally, include AoE in automated tests - e.g. ensure a deadline AoE appears one day later in GMT+12 zone.
- **Risk: Lack of User Awareness or Adoption.** Even if we build a great tool, researchers need to know about it. There's a risk that the target users simply don't find ConfRadar or don't incorporate it into their workflow, sticking to old habits or other tools.  
    **Mitigation:** Although more of a marketing/outreach issue, from the product side we can include features that encourage sharing and stickiness. For example, easy sharing of a conference entry (like a "Copy link" to a conference detail) so users can send it to colleagues, thereby organically spreading the word. We should also ensure SEO (search engine optimization) is considered - e.g. server-side rendering or pre-rendering of content so that searching "&lt;conference name&gt; deadline" might surface ConfRadar. On the engagement side, if we implement an email alert system (future plan), that can bring users back to the site regularly. Initially, making the site open and free (no login barrier) is itself a mitigation to drive adoption through ease of access.
- **Risk: Maintenance and Data Updates (Project Sustainability).** As noted in background, similar tools have faltered when maintainers moved on[\[9\]](https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca#:~:text=The%20tool%20itself%20isn%E2%80%99t%20technically,interface%20is%20barebones%20but%20functional). ConfRadar could face risk if the team cannot keep up with adding new conferences or updating the crawler for each year's sites.  
    **Mitigation:** Design the system (and organization around it) to make maintenance easier: e.g. adding a new conference should be as simple as adding its URL to a crawl list. The LLM extraction should be generalized to handle most formats, reducing manual work. Perhaps open-source parts of the data (like allow community contributions via GitHub as some trackers do[\[10\]](https://github.com/huggingface/ai-deadlines#:~:text=To%20keep%20things%20minimal%2C%20we,tier%20conferences%20in%20AI)) so the burden is shared - e.g. accept user pull requests or suggestions for new conferences. Internally, plan for someone each year to review upcoming conferences and ensure they're in the system. The change history and automated updates mitigate risk of stale data, but human oversight is still key.
- **Risk: Calendar Integration Issues.** There is a small risk that the ICS file or Google Calendar link might not work perfectly (could be due to ICS format issues or Google's interface changing). If events show at wrong times or not at all, users will lose confidence.  
    **Mitigation:** Follow the iCalendar standard strictly when generating ICS. Test the ICS import on major platforms (Google Calendar, Outlook, Apple Calendar) before release. We saw existing projects successfully offering ICS[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them), so we can use similar formatting. Also, if any known quirks (like Google Calendar not updating subscribed ICS often), inform users (maybe refresh instructions if needed). Keep the ICS updated and lightweight (maybe only upcoming deadlines) to avoid performance issues in calendar apps.
- **Risk: Legal or Ethical Issues.** Using content from conference websites (dates, etc.) is generally public information, but we should be mindful of any terms of use. Also, using an LLM for parsing might accidentally pick up text beyond just dates (like full CFP text, which might not be intended for redistribution).  
    **Mitigation:** We mostly store factual data (dates, locations) which are not copyrightable. We will not store large chunks of text from CFPs, only the metadata, so it should be fine. Still, if a conference requests removal or has a problem, we have a contact channel to address it. Ethically, we should ensure credit - for instance, linking to the official site is good practice. Also, we will not use any data for profit; ConfRadar is a productivity tool. As for LLM usage, ensure no sensitive or personal data is involved in the extraction (shouldn't be, as it's public info).
- **Risk: Feature Creep and Delays.** There's a risk of trying to add too many features (especially from the Future Roadmap) into v1, which could delay launch or complicate the product.  
    **Mitigation:** Stick to the core requirements for v1 as outlined. Use the priority designations to say no to adding low-priority features until the basics are solid. If during development we find something is taking too long (e.g. an overly complex filter UI), be prepared to simplify for v1 and perhaps revisit after launch. Keep stakeholders aligned with the scope using this PRD to avoid mid-cycle changes.

We will maintain a risk register during the project to continuously monitor these and any new risks. Regular team meetings will include a quick risk review, ensuring mitigations are on track (e.g. verifying data accuracy periodically, testing performance as data scales, etc.). By proactively addressing these risks, we aim to launch ConfRadar front-end smoothly and maintain its reliability and relevance over time.

## Dependencies

The ConfRadar front-end project depends on several external and internal components for full functionality. Understanding these dependencies is crucial for planning and coordinating development:

- **Back-end API & Database:** The primary dependency is the ConfRadar back-end system, which includes the web crawlers, LLM processing pipeline, database, and API server. The front-end cannot function without the API delivering conference data. We need the back-end team to define the API endpoints and data schema (as we've outlined) and ensure they're populated with data. Timing-wise, a stub or mock API should be available early for front-end development, and the real data should be ready by testing phase. If the back-end is delayed or the API contracts change, the front-end timeline might be affected.
- **LLM Extraction Pipeline:** Within the back-end, the LLM that extracts metadata is a dependency in the sense that the quality and frequency of data updates rely on it. For example, if the LLM has high latency or costs, it might limit how often data can refresh. From the front-end perspective, this affects how fresh data is and how often we might call the API for updates. We coordinate with the back-end to know, for instance, if updates happen twice a day, the front-end might not need to poll more frequently.
- **External Data Sources:** Conference websites themselves are an indirect dependency. If many conferences don't publish info in a timely manner or require manual intervention, that's a risk to data completeness. This isn't something the front-end team controls, but we should be aware of it. Similarly, any third-party API (like if we used the WikiCFP API or something for initial data) would be a dependency.
- **Time Zone Database/Library:** To handle time zone conversions (AoE, local time, etc.), we rely on accurate time zone data (like the IANA tz database). In the front-end, this likely means using a library (e.g. Luxon or date-fns-tz) which includes time zone definitions. Keeping that updated is important (e.g. daylight savings changes). This is a dependency managed via our chosen library's maintenance.
- **Calendar Integration Services:**
- For ICS, we depend on the iCalendar specification and the ability of user's calendar apps to subscribe. That's a standard and should be stable. We might use a library to generate ICS on the backend (e.g. ical4j or similar) - that's a back-end dependency.
- For Google Calendar integration, we depend on Google's URL scheme for adding calendars (which is a well-known interface and likely to remain available). We should verify it remains consistent.
- If we decide to directly use Google Calendar API (unlikely, since just providing ICS is easier), we'd have dependencies like Google API keys, etc. But as of now, just using the calendar URL with our ICS feed keeps things simpler and avoids deep integration dependency.
- **Map Service (if any):** If we show location maps or link to maps for conference venues, we depend on a mapping service. We currently plan just a link (like Google Maps link with coordinates or venue name, as seen in some trackers[\[7\]](https://blockchain-deadlines.github.io/#:~:text=June%2022,New%20York%20City%2C%20NY%2C%20USA)). That's minimal dependency (just that Google Maps link format remains valid). If we embedded a map, that would introduce dependency on Google Maps API or similar (which may require an API key and have usage limits). Likely not needed for v1.
- **Front-end Libraries/Frameworks:** The choice of front-end stack (e.g. React with certain UI component libraries, Redux or not, etc.) introduces dependencies:
- UI framework (React, Vue, etc.) - We rely on their continued support and updates. We'll lock to a stable version for the project duration.
- Component libraries or styling frameworks (maybe Material UI, Bootstrap, Tailwind, etc.) - If we use one, we depend on its availability and compatibility.
- Any chart or calendar libraries for special components (if we had a calendar view, we might use FullCalendar or similar).
- Date handling libraries as mentioned for time zones.
- These are all managed via our package manager and should be documented. We'll keep an eye on any critical bug updates in these libraries during development.
- **Deployment Infrastructure:** To deploy the front-end, we depend on infrastructure (maybe an AWS S3/CloudFront for a static SPA, or Vercel/Netlify for hosting). This dependency is on the ops side - ensuring we have an environment to host the app, and that the API endpoint is accessible (CORS enabled if on different domain, etc.). If our front-end is separate, we need the back-end to allow cross-origin requests or we deploy under the same domain.
- **Team and Knowledge:** A human dependency - making sure we have front-end developers with the skills (React, etc.) and that they communicate with back-end devs. Also, any domain knowledge from subject-matter experts (like knowing where to find conference info) is valuable - if those people are unavailable, it could slow down data input. We mitigate by documenting assumptions (like we have in this PRD from sources).

In managing dependencies, we plan for integration testing between front-end and back-end. For example, once the back-end API for /conferences is ready, front-end dev can integrate it and we'll have a joint test to ensure data flows correctly (e.g. does the JSON field match what front-end expects?). We'll use the API contracts defined here as the agreement; any changes must be communicated early.

Also, for third-party dependencies (libraries, etc.), we will lock versions and have a plan to update them post-launch to avoid last-minute surprises (e.g. a breaking change in a library right before release).

## Future Roadmap (Phase 2+)

After the initial version of ConfRadar is launched, there are several enhancements and new features that could be pursued to increase the value of the product. Below are some ideas for Phase 2 and beyond, which are outside the immediate scope of the current PRD but worth considering for the roadmap:

- **User Accounts and Personalized Alerts:** Allow users to create an account or profile where they can **subscribe to specific conferences or fields**. They could then set up personalized email notifications or in-app notifications for deadlines. For example, Alice could "follow" NeurIPS and ICML and get an email 1 month and 1 week before each deadline. The groundwork for this exists (the back-end could trigger emails), but it requires building user management, authentication, and preference storage. This feature would significantly increase user engagement by actively reminding them rather than relying on them to check the site[\[11\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=Suscr%C3%ADbete%20para%20recibir%20notificaciones%20por,correo%20electr%C3%B3nico%20y%20sus%20preferencias)[\[12\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=Preguntas%20frecuentes).
- **Collaboration & Sharing Features:** Introduce ways for users to share or discuss conferences. For instance, a feature to **"recommend to a colleague"** - maybe generate a sharable link or email template. Another idea is a comments or notes section on a conference detail page (though moderating that could be complex). A lighter approach: integration with social media - e.g. a "Tweet this deadline" button for those who want to share an upcoming deadline on Twitter, etc. This can help spread the word and also let users annotate information (e.g. someone might comment "This conference often extends deadlines" - useful context, though verifying such info is tricky).
- **Conference Addition Requests / Crowdsourcing:** In future, allow users to suggest a new conference that may not be in the system. This could be a form where they input basic info, which then our team verifies and adds (or if we trust power-users, possibly auto-add to a pending list). This leverages the community to cover more fields or smaller workshops that the core team might not have on the radar. It also creates a sense of community ownership.
- **Integration with External Data (Publications, Rankings):** Enhance each conference's detail page with additional info like acceptance rates, h-index metrics, or links to accepted papers. For example, pulling data from sources like CORE rankings or Google Scholar metrics to show conference prestige (some trackers have a field for h5-index[\[13\]](https://github.com/huggingface/ai-deadlines#:~:text=,the%20importance%20of%20a%20conference)). Or link to the conference proceedings once available, or to an openreview page if applicable. This turns ConfRadar into not just a deadline tracker, but a one-stop for conference info.
- **Calendar View and Timeline Visualizations:** Offer alternative views to visualize deadlines. A **calendar view** could show a month or year with deadlines marked on it (useful to avoid conflicts and see clustering of deadlines). A **timeline or Gantt-style view** might show how submission, notification, and conference dates relate (e.g. lines for each conference from submission to conference date). This can help researchers plan (e.g. see that if you submit in Jan, you'll know acceptance by Mar, conference in Jul). Graphical views require more UI work and perhaps introducing libraries for calendars or timeline charts.
- **Mobile App / Offline Support:** While the responsive web app will work on mobile browsers, a dedicated mobile app (iOS/Android) could provide a smoother experience and push notifications for deadlines. Alternatively, a Progressive Web App (PWA) approach could enable offline caching of data and push notifications (when deadlines are approaching). This way, users get alerts on their phone similar to how calendar reminders work.
- **AI Assistant for Queries:** Leverage the LLM capabilities not just for data extraction but for user interaction. For instance, a chatbot or query interface where a user can ask "Which security conferences have deadlines after March and are in Europe?" and get an answer, rather than manually filtering. This could be a natural language filter front-end to the same data. It could also handle queries like "What's the usual submission to notification duration for NeurIPS?" by computing from the data.
- **Multi-language Support:** Translate the interface (and perhaps even conference info) into other languages to cater to non-English-speaking researchers. The core data (conference names, etc.) will largely remain in English, but UI elements and any explanatory text could be localized. This could broaden adoption in regions where English isn't the primary language.
- **Admin Dashboard:** Develop an admin interface (internal) for the ConfRadar team to monitor the system - e.g. see logs of crawls, a list of conferences with missing data, or a UI to manually edit data if needed. This is not user-facing but ensures the system can be managed efficiently as it scales.
- **Enhanced Change Tracking and Alerts:** Extend the change history idea - maybe allow users to subscribe to changes. For example, "Notify me if this deadline changes." That way, if a deadline extension is detected, an email or notification is sent out immediately. This overlaps with personalized alerts but is specific to changes (which can be critical when an extension gives extra time unexpectedly).
- **Conference Comparison Feature:** Allow users to select multiple conferences and compare them side by side - for example, to decide which fits their schedule. This comparison could show deadlines, conference dates, location, etc. If someone has two potential targets, they can quickly see "Conference A deadline vs Conference B deadline vs their notification dates" to strategize.
- **Historical Data and Analytics:** Over time, ConfRadar will accumulate historical data on conferences (past deadlines, how they shift year to year). We could add a section for insights, like "Deadline trends: Conference X's deadline is ~5 days later each year" or "Number of conferences in AI has grown 20% over 5 years," etc. While this veers into analysis, it could be an interesting feature for the community (perhaps more for curiosity or academic analysis than practical use).
- **Sponsorship/Partnership Integrations:** (Just a note for long-term sustainability) We might consider integrating with conference organizers or sponsors. For example, a conference could "claim" their listing on ConfRadar to add official updates or a message. Or a partner like a journal might promote special issues. These have to be carefully done to maintain neutrality, but just a possible future avenue.

Phase 2 features should be prioritized based on user feedback after v1 launch. We expect that user requests will guide us - e.g. if many say "I wish I could get email reminders," that bumps the alerts feature priority. The roadmap above ensures that ConfRadar can evolve from a simple tracker to a comprehensive platform for conference-related planning and analysis, all while keeping researchers' needs at the core.

## Documentation & Deliverables

To ensure successful implementation and adoption of ConfRadar, we will prepare a set of documentation and deliverables for both developers and end-users:

- **Product Requirements Document (PRD):** _(This document)_ - Serves as the authoritative reference for what the front-end should do. It will be shared with the development team and stakeholders. It remains a living reference during development to prevent scope creep and to check off fulfilled requirements.
- **Technical Design Document (Frontend):** After the PRD sign-off, the development team may produce a more technical design spec for the front-end architecture. This could include component hierarchy, state management strategy, API interaction details, and any algorithms (e.g. for time conversion). It ensures all developers have a clear plan to follow, especially if the team is larger.
- **API Documentation (Swagger/OpenAPI):** A comprehensive reference for all API endpoints, their request and response formats, including examples. This is critical for the front-end dev to understand back-end inputs/outputs, and also serves external developers if one day an API is public. We might use Swagger UI or similar to host interactive docs. For example, documenting that deadlines.timezone can be "AoE" meaning UTC-12[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33), etc., so devs know how to handle it.
- **User Guide / Help Documentation:** Create a concise guide for end-users (researchers) explaining how to use ConfRadar. This might be a webpage or PDF that covers: how to search/filter, what AoE means, how to export to calendar, and FAQs. For instance, an FAQ entry could be "Q: What does AoE mean? A: AoE stands for Anywhere on Earth - the deadline hasn't passed until it's passed everywhere[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33)." Another could be "How do I add deadlines to my Google Calendar?" with step-by-step instructions. This guide will be available on the site (perhaps under a Help section).
- **Release Notes / Changelog:** As we launch and update, maintain a changelog for internal and possibly external visibility. It lists what features were added, changes, or fixed in each version. This is useful for developers and users to know what's new or different (e.g. "v1.1: Added sort by deadline feature").
- **Test Plan and Test Cases:** A document outlining how we will test each functional requirement. It will list test cases (e.g. "Verify that filtering by location=Europe only shows European conference entries") and expected results. This ensures QA covers all features. It may also include performance testing scenarios (e.g. test with 1000 conferences loaded) and cross-browser testing matrix (list of browsers/devices and test status). This is more for internal use but is essential deliverable for quality assurance.
- **Wireframes and UI Mockups:** Early in design, we will deliver wireframes or mockups of the UI. As we iterate, high-fidelity mockups for critical pages (list and detail) can be produced, possibly using design tools (Figma, Adobe XD). These serve as a visual guide for developers and a reference in case of disputes on how something should look or behave. Post-implementation, updated screenshots could be included in user documentation.
- **Frontend Source Code Repository:** The actual deliverable code, likely hosted in a version control system (GitHub, GitLab). This includes all source code, configuration, and build scripts. It should be well-documented with comments, and include a README for developers on how to set up and run the project locally. We might also provide a brief architecture note in the repo's README to orient new contributors.
- **Deployment Scripts/Configuration:** Documentation or scripts to deploy the front-end. For example, if using Docker or a specific hosting, provide Dockerfiles or CI/CD pipeline configs. This ensures the operations side can reliably deploy new versions. If using a service like Netlify or Vercel, document the environment settings (like API base URL) and any build commands.
- **Analytics Setup Documentation:** If we integrate any analytics (for capturing metrics as discussed in Success Metrics), document what tools are used (e.g. Google Analytics or a self-hosted Matomo) and how events are defined (so we know how to interpret the tracked events).
- **Maintenance Guide:** A brief document for maintainers (which might be internal) on how to update the conference list if needed manually, or how to update dependencies safely. It might include contact info for key systems (like if the LLM API key expires, who to call). Essentially, anything unique in running ConfRadar should be recorded so that if the original developers roll off, new ones can pick it up.
- **Legal/Privacy Documentation:** If applicable, a privacy policy (especially if we add user accounts or tracking). For now, probably not needed beyond maybe stating that we don't collect personal data (assuming no login). But if down the line we have user emails for alerts, a privacy policy and terms of service will be necessary deliverables.

All documentation should be written in clear language appropriate to its audience. Developer docs can be more technical, while user-facing guides must be simple and jargon-free. We will also ensure the **citations and attributions** are properly noted in the documentation (for example, acknowledging any external data or libraries, and clarifying terms like AoE came from a known definition[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33)).

Finally, deliverables include the **working application** itself. A demo or staging URL will be provided during development, and the final production deployment (with domain name configured) is the ultimate deliverable for users. We consider the project delivered when users can access ConfRadar in their browsers and find it meeting their needs, with all supporting documentation available for reference.

## Architecture Overview

ConfRadar's overall architecture follows a classic web application model, with a clear separation between the front-end client and back-end services. Below is a high-level overview of how the components interact and how data flows:

- **Client-side (Frontend Web App):** This is the part described in this PRD - a single-page application (SPA) built with modern web technologies (e.g. React). The front-end is responsible for the user interface: displaying conference data, handling user interactions (search, filters, clicks), and presenting results. It does not have its own persistent data storage; it fetches data as needed from the back-end via HTTP requests. The front-end code will likely be served as static files (HTML/JS/CSS) from a web server or CDN. When a user visits the ConfRadar site, these files load in their browser, and the SPA takes over routing (allowing smooth transitions between the conference list view and detail view without full page reloads).
- **Server-side (Backend API and Data Pipeline):** The back-end consists of several sub-components:
- **Web Crawler & Scraper:** A scheduled process (or set of processes) that fetches conference information from various sources. This could be a combination of custom scrapers for known conference websites and a general crawler that finds new CFP announcements. The crawler likely stores raw HTML or text for processing.
- **LLM-based Metadata Extractor:** This is an automated agent that takes the raw content (e.g. a CFP page text) and uses a Large Language Model to parse out structured fields (deadline dates, location, etc.). For instance, if the crawler pulls a call-for-papers PDF, the LLM might be prompted with "Extract the submission deadline, notification date, venue, etc." and it outputs those. The extracted data is then structured into the conference data model. We likely have a set of rules or prompts to ensure consistency across conferences.
- **Database:** A database (SQL or NoSQL) that stores all the conference records. Each record corresponds to a conference edition (e.g. ICML 2026 as one entry) with all its metadata and dates. Change history might be stored as related records or a versioning table. The choice of DB might be something like PostgreSQL (for relational structure) or a document DB since each conference has nested fields like deadlines array.
- **API Server:** A web service (could be a REST API built with Node, Django, Flask, etc.) that queries the database and serves data to the front-end. It implements endpoints such as /api/conferences and /api/conferences/{id} as described. It may also handle ICS generation - e.g., when /api/calendar/ics is hit, the API server will gather the relevant conferences' deadlines and format them into an ICS file on the fly (or perhaps generate this file periodically and serve it statically).
- **Integration/Workflow:**
- **Data Update Flow:** The crawler + LLM pipeline likely runs periodically (e.g. daily or when triggered by detection of new info). When it runs, it updates the database. For example, it might find a new conference or update an existing one's deadline. The system could log changes (populating the change_history). These updates happen in the background without direct user involvement. A note from an existing system: one project used a CRON job (via GitHub action) to automatically update conference data from a source repository[\[14\]](https://github.com/huggingface/ai-deadlines#:~:text=New%20data%20is%20fetched%20from,thanks%20to%20%20101) - similarly, we can schedule our pipeline to ensure fresh data.
- **Client Request Flow:** When a user visits the site and requests data (say they open the conference list), the front-end calls the API server (HTTPS request). The API server queries the database for the list of conferences (possibly applying filters if query params provided), and returns JSON. The front-end receives this and renders the UI accordingly. If the user then navigates to a detail page, another API call fetches details for that conference.
- **Calendar Export Flow:** If the user clicks to add to Google Calendar (which essentially means Google's servers will fetch our ICS URL) or to download ICS, the request hits the /api/calendar/ics endpoint. The API server then likely queries the database for all upcoming deadlines (or uses cached results), generates an ICS file (a text format) and returns it. In the Google Calendar scenario, Google acts as a client to our API, retrieving the ICS. The front-end's role was just to direct to that link.
- **Architecture Diagram Description:** If visualized, the architecture might look like:
- Users access the **SPA** via their Browser. The SPA is served from a **Web Server** (could be Nginx or a static site host).
- The SPA (front-end) communicates with the **API Server** over HTTPS for data. Each request goes to the server, which then interacts with the **Database** to fetch or update data.
- In the background, separate from user requests, the **Crawler/LLM Service** also interacts with the Database (writing new data). It might also call external URLs (conference sites) and use an **LLM API** (possibly OpenAI or a local model) as needed. We ensure the crawler doesn't interfere with the API's reads - typically managed by the DB concurrency (and since writes are not too frequent or heavy).
- For ICS, the API server might also generate and cache some ICS files on disk or in memory, which the Web Server can serve directly after the first generation, to reduce load.
- **Scaling Considerations:** The front-end is static and can scale by simply serving files via CDN. The API server and DB are what scale with usage and data size. If load grows, we can scale the API horizontally behind a load balancer and ensure the DB can handle read traffic (maybe implement read replicas). The crawler/LLM pipeline might be decoupled (for example, using a message queue - when new URLs are found, a worker picks them up to process).
- **Security & CORS:** The front-end domain (say conf-radar.com) will make AJAX calls to the API domain. If they are the same domain, cookies or tokens could be used (though we have no auth currently). If different, we will enable CORS on the API. Since we have no user login, security mainly means protecting the back-end endpoints from abuse (maybe rate-limit the API if needed, to prevent misuse of ICS feed or scrapers hitting our API).
- **Logging/Monitoring:** The architecture will include logging on both front-end (for errors, possibly via an error tracking service) and back-end (for request logs, error logs). Monitoring might include uptime checks on the API, and performance monitoring in the browser (using something like Google Analytics or Sentry for error capturing). This ensures we can detect if any part of the system (like the API or data pipeline) is failing and affecting users.

In essence, the front-end is a consumer of the back-end's data services, and the back-end is the engine keeping that data fresh. The LLM integration is a distinctive part of this architecture: instead of purely manual or regex-based scraping, it uses AI to interpret content. This adds some complexity in the data layer, but by the time it reaches the front-end, it's just structured data.

**Development Approach:** We will likely develop and test the front-end against a staging instance of the back-end. The architecture allows independent work - front-end can use mock data if back-end is not ready, and back-end can be tested with tools like curl or Postman. Continuous integration can run tests for each (front-end unit tests, back-end tests). When deploying, we'll deploy back-end API and ensure it's stable, then deploy front-end (since front-end has less risk in deployment). We also plan a **staging environment** where the whole system is integrated for final testing by the team before going live.

By keeping the architecture modular, each part (crawling, data extraction, API serving, front-end UI) can be scaled or modified with minimal impact on others. For example, if in the future the LLM extraction is replaced or enhanced, as long as the final database schema/API doesn't break, the front-end continues to work. Similarly, if we build a mobile app, it could use the same API. This separation of concerns is aligned with modern web app architecture practices[\[15\]](https://acropolium.com/blog/modern-web-app-architecture/#:~:text=The%20main%20components%20of%20web,and%20see%20how%20they), yielding a robust and extensible system.

[\[1\]](https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca#:~:text=People%20often%20ask%20where%20to,has%20been%20adopted%20by%20HuggingFace) [\[9\]](https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca#:~:text=The%20tool%20itself%20isn%E2%80%99t%20technically,interface%20is%20barebones%20but%20functional) People often ask where to check AI conference deadlines - it was previously maintained by PapersWithCode, but now this feature has been adopted by HuggingFace. The tool itself isn't technically - AI Engineering - Medium

<https://ai-engineering-trend.medium.com/the-migration-history-of-ai-conference-deadline-tracking-tools-1344fa8c60ca>

[\[2\]](https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline#:~:text=33) Timezone of "AoE" for a conference submission deadline? - Academia Stack Exchange

<https://academia.stackexchange.com/questions/54612/timezone-of-aoe-for-a-conference-submission-deadline>

[\[3\]](https://blockchain-deadlines.github.io/#:~:text=Deadlines%20are%20shown%20in%20America%2FNew_York,website%20timezones%2C%20click%20on%20them) [\[7\]](https://blockchain-deadlines.github.io/#:~:text=June%2022,New%20York%20City%2C%20NY%2C%20USA) Blockchain Deadlines

<https://blockchain-deadlines.github.io/>

[\[4\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C3%89xito%20de%20los%20estudiantes%20doctorales) [\[5\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=%C2%BFCon%20qu%C3%A9%20frecuencia%20se%20actualizan,los%20datos%20de%20las%20reuniones) [\[11\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=Suscr%C3%ADbete%20para%20recibir%20notificaciones%20por,correo%20electr%C3%B3nico%20y%20sus%20preferencias) [\[12\]](https://www.gadegetkit.com/es/tools/public-tools/conferences#:~:text=Preguntas%20frecuentes) Recordatorios gratuitos de conferencias | Fecha lmite de conferencias acadmicas 2024 | Todos los recordatorios de conferencias

<https://www.gadegetkit.com/es/tools/public-tools/conferences>

[\[6\]](https://github.com/huggingface/ai-deadlines#:~:text=You%20can%20add%20any%20custom,in%20the%20conference%20details%20card) [\[8\]](https://github.com/huggingface/ai-deadlines#:~:text=src%2Fdata%2Fconferences%2F,the%20importance%20of%20a%20conference) [\[10\]](https://github.com/huggingface/ai-deadlines#:~:text=To%20keep%20things%20minimal%2C%20we,tier%20conferences%20in%20AI) [\[13\]](https://github.com/huggingface/ai-deadlines#:~:text=,the%20importance%20of%20a%20conference) [\[14\]](https://github.com/huggingface/ai-deadlines#:~:text=New%20data%20is%20fetched%20from,thanks%20to%20%20101) GitHub - huggingface/ai-deadlines:  AI conference deadline countdowns

<https://github.com/huggingface/ai-deadlines>

[\[15\]](https://acropolium.com/blog/modern-web-app-architecture/#:~:text=The%20main%20components%20of%20web,and%20see%20how%20they) Modern Web Application Architecture to Build a High-Performance ...

<https://acropolium.com/blog/modern-web-app-architecture/>